#include "infrastructure/OllamaAdapter.hpp"
#include <httplib.h>
#include <nlohmann/json.hpp>
#include <iostream>
#include <chrono>
#include <iomanip>
#include <sstream>

using json = nlohmann::json;

namespace ideawalker::infrastructure {

OllamaAdapter::OllamaAdapter(const std::string& host, int port)
    : m_host(host), m_port(port) {}

std::optional<domain::Insight> OllamaAdapter::processRawThought(const std::string& rawContent) {
    httplib::Client cli(m_host, m_port);
    cli.set_read_timeout(60); // LLMs take time

    json requestData = {
        {"model", m_model},
        {"prompt", "Você é um assistente TDAH. Estruture o seguinte pensamento em Markdown com as seções: # Título, ## Insight Central, ## Pontos Principais, ## Ações, ## Conexões. Texto:\n\n" + rawContent},
        {"stream", false}
    };

    auto res = cli.Post("/api/generate", requestData.dump(), "application/json");

    if (res && res->status == 200) {
        try {
            auto body = json::parse(res->body);
            std::string responseText = body.value("response", "");

            // Simple metadata generation for now
            auto now = std::chrono::system_clock::now();
            auto in_time_t = std::chrono::system_clock::to_time_t(now);
            std::stringstream ss;
            ss << std::put_time(std::localtime(&in_time_t), "%Y-%m-%d %X");

            domain::Insight::Metadata meta;
            meta.id = std::to_string(in_time_t);
            meta.title = "Structured Thought";
            meta.date = ss.str();
            meta.tags = {"#AutoGenerated"};

            return domain::Insight(meta, responseText);
        } catch (...) {
            return std::nullopt;
        }
    }

    return std::nullopt;
}

} // namespace ideawalker::infrastructure
